import numpy as np
import os
from typing import List, Dict, Any, Optional, Union
from rank_bm25 import BM25Okapi
from loguru import logger
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

class HybridSearcher:
    """
    ç»Ÿä¸€æ··åˆæ£€ç´¢å¼•æ“ (Hybrid RAG)
    å®ç° BM25 (æ–‡æœ¬) + å‘é‡ (è¯­ä¹‰) çš„èåˆæœç´¢ (RRF)
    """
    
    def __init__(self, data: List[Dict[str, Any]], text_fields: List[str] = ["title", "content"], model_name: str = None):
        """
        åˆå§‹åŒ–æœç´¢å™¨
        
        Args:
            data: æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º Dict
            text_fields: ç”¨äºå»ºç«‹ç´¢å¼•çš„æ–‡æœ¬å­—æ®µ
            model_name: å‘é‡æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ paraphrase-multilingual-MiniLM-L12-v2
        """
        self.data = data
        self.text_fields = text_fields
        self._corpus = []
        self._bm25 = None
        self._vector_model = None
        self._embeddings = None
        self._fitted = False
        self._vector_fitted = False
        
        # é»˜è®¤æ¨¡å‹
        self.model_name = model_name or os.getenv("EMBEDDING_MODEL", "paraphrase-multilingual-MiniLM-L12-v2")
        
        if data:
            self._prepare_corpus()
            self._fit_bm25()
            # å»¶è¿ŸåŠ è½½å‘é‡æ¨¡å‹ï¼Œä»…åœ¨éœ€è¦æ—¶æˆ–åˆå§‹åŒ–æ—¶æ˜¾å¼è°ƒç”¨
            # self._fit_vector() 

    def _prepare_corpus(self):
        """å‡†å¤‡è¯­æ–™åº“ç”¨äºåˆ†è¯"""
        import jieba  # ä½¿ç”¨ jieba è¿›è¡Œä¸­æ–‡åˆ†è¯
        
        self._corpus = []
        self._full_texts = []
        for item in self.data:
            text = " ".join([str(item.get(field, "")) for field in self.text_fields])
            self._full_texts.append(text)
            # ä¸­æ–‡åˆ†è¯ä¼˜åŒ–
            tokens = list(jieba.cut(text))
            self._corpus.append(tokens)

    def _fit_bm25(self):
        """è®­ç»ƒ BM25 æ¨¡å‹"""
        if self._corpus:
            self._bm25 = BM25Okapi(self._corpus)
            self._fitted = True
            logger.info(f"âœ… BM25 index fitted with {len(self.data)} documents")

    def _fit_vector(self):
        """è®­ç»ƒå‘é‡æ¨¡å‹å¹¶ç”Ÿæˆ Embeddings"""
        if not self.data:
            return
            
        try:
            logger.info(f"ğŸ“¡ Loading embedding model: {self.model_name}...")
            self._vector_model = SentenceTransformer(self.model_name)
            logger.info(f"ğŸ§  Encoding {len(self._full_texts)} documents...")
            self._embeddings = self._vector_model.encode(self._full_texts, show_progress_bar=False)
            self._vector_fitted = True
            logger.info("âœ… Vector index fitted successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to fit vector index: {e}")
            self._vector_fitted = False

    def _compute_rrf(self, rank_lists: List[List[int]], k: int = 60) -> List[tuple]:
        """
        è®¡ç®— Reciprocal Rank Fusion (RRF)
        
        Args:
            rank_lists: å¤šä¸ªæ’åºåçš„ç´¢å¼•åˆ—è¡¨
            k: RRF å¸¸æ•°ï¼Œé»˜è®¤ 60
        """
        scores = {}
        for rank_list in rank_lists:
            for rank, idx in enumerate(rank_list):
                if idx not in scores:
                    scores[idx] = 0
                scores[idx] += 1.0 / (k + rank + 1)
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_indices = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_indices

    def search(self, query: str, top_n: int = 5, use_vector: bool = False) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œæ··åˆæœç´¢
        
        Args:
            query: æœç´¢å…³é”®è¯
            top_n: è¿”å›ç»“æœæ•°é‡
            use_vector: æ˜¯å¦å¯ç”¨å‘é‡æœç´¢
        """
        if not self._fitted or not query:
            return []
        
        import jieba
        query_tokens = list(jieba.cut(query))
        
        # 1. BM25 æœç´¢ç»“æœ
        bm25_scores = self._bm25.get_scores(query_tokens)
        bm25_rank = np.argsort(bm25_scores)[::-1].tolist()
        
        rank_lists = [bm25_rank]
        
        # 2. å‘é‡æœç´¢é€»è¾‘
        if use_vector:
            if not self._vector_fitted:
                self._fit_vector()
            
            if self._vector_fitted:
                query_embedding = self._vector_model.encode([query], show_progress_bar=False)
                similarities = cosine_similarity(query_embedding, self._embeddings)[0]
                vector_rank = np.argsort(similarities)[::-1].tolist()
                rank_lists.append(vector_rank)
            else:
                logger.warning("Vector search requested but model not fitted, falling back to BM25")
        
        # 3. èåˆæ’åº (RRF)
        if len(rank_lists) > 1:
            rrf_results = self._compute_rrf(rank_lists)
            # RRF è¿”å› (idx, score) åˆ—è¡¨
            final_rank = [idx for idx, score in rrf_results]
        else:
            final_rank = bm25_rank
        
        # è¿”å›å‰ top_n æ¡ç»“æœ
        results = [self.data[idx].copy() for idx in final_rank[:top_n]]
        
        # ä¸ºæ¯ä¸ªç»“æœæ³¨å…¥ç›¸å…³æ€§è¯„åˆ†
        for i, res in enumerate(results):
            try:
                original_idx = final_rank[i]
                res["_search_score"] = bm25_scores[original_idx]
                if use_vector and self._vector_fitted:
                    res["_vector_score"] = float(similarities[original_idx])
            except:
                res["_search_score"] = 0
            
        return results

class InMemoryRAG(HybridSearcher):
    """ä¸“é—¨ç”¨äº ReportAgent è·¨ç« èŠ‚æ£€ç´¢çš„å†…å­˜æ€ RAG"""
    
    def search(self, query: str, top_n: int = 3, use_vector: bool = True) -> List[Dict[str, Any]]:
        """é»˜è®¤å¼€å¯å‘é‡æœç´¢çš„å†…å­˜æ£€ç´¢"""
        return super().search(query, top_n=top_n, use_vector=use_vector)

    def update_data(self, new_data: List[Dict[str, Any]]):
        """åŠ¨æ€æ›´æ–°æ•°æ®å¹¶é‡æ–°è®­ç»ƒç´¢å¼•"""
        self.data = new_data
        self._prepare_corpus()
        self._fit_bm25()
        # å¦‚æœä¹‹å‰å·²ç»åŠ è½½è¿‡å‘é‡æ¨¡å‹ï¼Œåˆ™æ›´æ–°å‘é‡ç´¢å¼•
        if self._vector_model:
            self._fit_vector()
        logger.info(f"ğŸ”„ InMemoryRAG updated with {len(new_data)} items")

class LocalNewsSearch(HybridSearcher):
    """æŒä¹…æ€ RAGï¼šæ£€ç´¢æ•°æ®åº“ä¸­çš„å†å²æ–°é—»"""
    
    def __init__(self, db_manager):
        """
        Args:
            db_manager: DatabaseManager å®ä¾‹
        """
        self.db = db_manager
        # åˆå§‹æ—¶ä¸åŠ è½½æ•°æ®ï¼Œéœ€è°ƒç”¨ load_history
        super().__init__([], ["title", "content"])
    
    def load_history(self, days: int = 30, limit: int = 1000):
        """ä»æ•°æ®åº“åŠ è½½æœ€è¿‘ N å¤©çš„æ–°é—»æ„å»ºç´¢å¼•"""
        try:
            # å‡è®¾ db_manager æœ‰ execute_query
            query = f"SELECT title, content, publish_time, source FROM daily_news ORDER BY publish_time DESC LIMIT ?"
            results = self.db.execute_query(query, (limit,))
            
            data = []
            for row in results:
                # è½¬æ¢ Row ä¸º Dict
                if hasattr(row, 'keys'):
                    item = dict(row)
                else:
                    item = {
                        "title": row[0], 
                        "content": row[1], 
                        "publish_time": row[2],
                        "source": row[3]
                    }
                data.append(item)
            
            self.data = data
            self._prepare_corpus()
            self._fit_bm25()
            # é»˜è®¤ä¸ç«‹å³è®­ç»ƒå‘é‡ï¼Œç­‰åˆ°ç¬¬ä¸€æ¬¡æœç´¢æ—¶æŒ‰éœ€è®­ç»ƒ
            logger.info(f"ğŸ“š LocalNewsSearch loaded {len(data)} items from history")
        except Exception as e:
            logger.error(f"Failed to load history for search: {e}")

    def search(self, query: str, top_n: int = 5, use_vector: bool = True) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæœ¬åœ°å†å²æœç´¢ï¼Œé»˜è®¤å¼€å¯å‘é‡æœç´¢"""
        if not self.data:
            self.load_history()
        return super().search(query, top_n=top_n, use_vector=use_vector)
