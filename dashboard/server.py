"""
AlphaEar Dashboard - ç®€åŒ–ç‰ˆæœåŠ¡ç«¯
åªä¿ç•™çœŸå® Agent æ¨¡å¼ï¼Œæ”¯æŒå†å²è®°å½•å’Œ Query è·Ÿè¸ª
"""
import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict, Any
from loguru import logger

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

from dotenv import load_dotenv
load_dotenv()

from .models import RunRequest, RunResponse, DashboardRun, DashboardStep, HistoryItem, QueryGroup
from .db import get_db
from utils.database_manager import DatabaseManager
from utils.news_tools import NewsNowTools



# ============ å…¨å±€çŠ¶æ€ç®¡ç† ============
class RunState:
    """å½“å‰è¿è¡ŒçŠ¶æ€"""
    def __init__(self):
        self.current_run_id: Optional[str] = None
        self.status: str = "idle"
        self.phase: str = ""
        self.progress: int = 0
        self.output: Optional[str] = None  # æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        self.report_structured: Optional[dict] = None
        self.connections: List[WebSocket] = []
        
        # ç¼“å­˜æ•°æ®ï¼ˆç”¨äº WebSocket æ¨é€ï¼‰
        self.signals: List[Dict] = []
        self.charts: Dict[str, Dict] = {}
        self.transmission_graph: Dict = {}
    
    async def broadcast(self, message: dict):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥"""
        dead_connections = []
        for ws in self.connections:
            try:
                await ws.send_json(message)
            except:
                dead_connections.append(ws)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for ws in dead_connections:
            if ws in self.connections:
                self.connections.remove(ws)
    
    def reset(self, run_id: str):
        self.current_run_id = run_id
        self.status = "running"
        self.phase = "åˆå§‹åŒ–"
        self.progress = 0
        self.output = None
        self.report_structured = None
        self.signals = []
        self.charts = {}
        self.transmission_graph = {}

run_state = RunState()

_news_db: Optional[DatabaseManager] = None
_news_tools: Optional[NewsNowTools] = None


def get_news_tools() -> NewsNowTools:
    global _news_db, _news_tools
    if _news_tools is None:
        _news_db = DatabaseManager()
        _news_tools = NewsNowTools(_news_db)
    return _news_tools

# ... (FastAPI setup omitted in replace context if not changing) ...


# ============ FastAPI App ============
async def lifespan(app: FastAPI):
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   AlphaEar Dashboard - Real Agent Mode                    â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸŒ Dashboard: http://localhost:8765                      â•‘
    â•‘  ğŸ“¡ WebSocket: ws://localhost:8765/ws                     â•‘
    â•‘  ğŸ“š API Docs:  http://localhost:8765/docs                 â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    yield
    print("ğŸ‘‹ Dashboard shutting down")


app = FastAPI(title="AlphaEar Dashboard", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============ WebSocket ============
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    run_state.connections.append(websocket)
    db = get_db()
    
    # å‘é€åˆå§‹çŠ¶æ€
    running_task = db.get_running_task()
    if running_task:
        steps = db.get_steps(running_task.run_id, limit=100)
        # Filter out charts without valid prices to prevent frontend crashes
        valid_charts = {
            k: v for k, v in run_state.charts.items()
            if v and isinstance(v.get("prices"), list) and len(v.get("prices", [])) > 0
        }
        await websocket.send_json({
            "type": "init",
            "data": {
                "run_id": running_task.run_id,
                "status": running_task.status,
                "query": running_task.query,
                "steps": [s.model_dump() for s in steps],
                "signals": run_state.signals,
                "charts": valid_charts,
                "graph": run_state.transmission_graph
            }
        })
    else:
        await websocket.send_json({
            "type": "init",
            "data": {
                "run_id": None,
                "status": "idle",
                "query": None,
                "steps": [],
                "signals": [],
                "charts": {},
                "graph": {}
            }
        })
    
    try:
        while True:
            data = await websocket.receive_text()
            msg = json.loads(data)
            
            # å¤„ç†å®¢æˆ·ç«¯å‘½ä»¤
            if msg.get("command") == "get_history":
                history = db.get_history(limit=50)
                await websocket.send_json({
                    "type": "history",
                    "data": [h.model_dump() for h in history]
                })
            
            elif msg.get("command") == "get_query_groups":
                groups = db.get_query_groups(limit=20)
                await websocket.send_json({
                    "type": "query_groups",
                    "data": [g.model_dump() for g in groups]
                })
            
            elif msg.get("command") == "get_run_details":
                run_id = msg.get("run_id")
                if run_id:
                    run = db.get_run(run_id)
                    steps = db.get_steps(run_id)
                    await websocket.send_json({
                        "type": "run_details",
                        "data": {
                            "run": run.model_dump() if run else None,
                            "steps": [s.model_dump() for s in steps]
                        }
                    })
            
            elif msg.get("command") == "get_status":
                # è¿”å›å½“å‰è¿è¡ŒçŠ¶æ€ï¼Œç”¨äºé¡µé¢åˆ·æ–°ååŒæ­¥
                from .integration import workflow_runner
                
                # æ­¥éª¤éœ€è¦ä»æ•°æ®åº“è·å–
                steps_data = []
                if run_state.current_run_id:
                    steps = db.get_steps(run_state.current_run_id)
                    steps_data = [s.model_dump() for s in steps]
                
                # Filter out charts without valid prices
                valid_charts = {
                    k: v for k, v in run_state.charts.items()
                    if v and isinstance(v.get("prices"), list) and len(v.get("prices", [])) > 0
                }
                
                await websocket.send_json({
                    "type": "init",
                    "data": {
                        "run_id": run_state.current_run_id,
                        "status": run_state.status,
                        "phase": run_state.phase,
                        "progress": run_state.progress,
                        "steps": steps_data,
                        "signals": run_state.signals,
                        "charts": valid_charts,
                        "graph": run_state.transmission_graph,
                        "is_running": workflow_runner.is_running()
                    }
                })
    
    except WebSocketDisconnect:
        if websocket in run_state.connections:
            run_state.connections.remove(websocket)


# ============ REST API ============
@app.post("/api/run", response_model=RunResponse)
async def start_run(request: RunRequest):
    """å¯åŠ¨æ–°çš„åˆ†æä»»åŠ¡"""
    db = get_db()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ (åŒé‡æ£€æŸ¥: å†…å­˜çŠ¶æ€ + æ•°æ®åº“)
    if run_state.status == "running":
        raise HTTPException(400, f"å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ: {run_state.run_id}")
    
    # æ¸…ç†æ•°æ®åº“ä¸­çš„åƒµå°¸è¿è¡Œè®°å½• (æœåŠ¡å™¨é‡å¯åé—ç•™çš„ running çŠ¶æ€)
    stale_running = db.get_running_task()
    if stale_running:
        logger.warning(f"âš ï¸ Found stale running task {stale_running.run_id}, marking as failed")
        db.update_run(stale_running.run_id, status="failed")
    
    # åˆ›å»ºæ–°è¿è¡Œè®°å½•
    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    sources_value = request.sources
    if isinstance(sources_value, list):
        sources_list = sources_value
        sources_text = ",".join(sources_value)
    else:
        sources_text = sources_value or "financial"
        sources_list = [s.strip() for s in sources_text.split(",") if s.strip()]

    run = DashboardRun(
        run_id=run_id,
        query=request.query,
        sources=sources_text,
        status="running",
        started_at=datetime.now().isoformat()
    )
    if request.query:
        latest = db.get_latest_run_by_query(request.query)
        if latest and latest.run_id != run_id:
            run.parent_run_id = latest.run_id
    db.create_run(run)
    
    # é‡ç½®çŠ¶æ€
    run_state.reset(run_id)
    
    # å¯åŠ¨å·¥ä½œæµ
    asyncio.create_task(execute_workflow(run_id, request))
    
    return RunResponse(run_id=run_id, status="started", query=request.query)


@app.get("/api/status")
async def get_status():
    """è·å–å½“å‰çŠ¶æ€"""
    from .integration import workflow_runner
    return {
        "run_id": run_state.current_run_id,
        "status": run_state.status,
        "phase": run_state.phase,
        "progress": run_state.progress,
        "signal_count": len(run_state.signals),
        "chart_count": len(run_state.charts),
        "is_running": workflow_runner.is_running(),
        "is_cancelled": workflow_runner.is_cancelled()
    }


@app.post("/api/run/cancel")
async def cancel_run():
    """å–æ¶ˆå½“å‰è¿è¡Œçš„å·¥ä½œæµ"""
    from .integration import workflow_runner
    
    # æ£€æŸ¥å®é™…å·¥ä½œæµçŠ¶æ€
    if workflow_runner.is_running():
        if workflow_runner.cancel():
            run_state.status = "cancelling"
            await run_state.broadcast({
                "type": "status",
                "data": {"status": "cancelling", "message": "æ­£åœ¨å–æ¶ˆ..."}
            })
            return {"success": True, "message": "å·²å‘é€å–æ¶ˆè¯·æ±‚"}
        return {"success": False, "message": "å–æ¶ˆå¤±è´¥"}
    
    # å·¥ä½œæµæœªè¿è¡Œï¼Œä½†å‰ç«¯çŠ¶æ€å¯èƒ½è¿‡æœŸ - é‡ç½®çŠ¶æ€
    if run_state.status == "running":
        logger.warning("âš ï¸ Frontend state was stale (running), resetting to idle")
        run_state.status = "idle"
        await run_state.broadcast({
            "type": "status", 
            "data": {"status": "idle", "message": "çŠ¶æ€å·²é‡ç½®"}
        })
        return {"success": True, "message": "çŠ¶æ€å·²é‡ç½®ï¼ˆæ— è¿è¡Œä¸­ä»»åŠ¡ï¼‰"}
    
    return {"success": False, "message": "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"}


@app.get("/api/history", response_model=List[HistoryItem])
async def get_history(limit: int = 50):
    """è·å–å†å²è¿è¡Œåˆ—è¡¨"""
    db = get_db()
    return db.get_history(limit=limit)


@app.get("/api/query-groups", response_model=List[QueryGroup])
async def get_query_groups(limit: int = 20):
    """æŒ‰ Query åˆ†ç»„è·å–å†å²"""
    db = get_db()
    return db.get_query_groups(limit=limit)


@app.get("/api/hot-news")
async def get_hot_news(sources: str = "cls,wallstreetcn,xueqiu", count: int = 8):
    """è·å–çƒ­ç‚¹æ–°é—»ï¼ˆç»“æ„åŒ–ï¼‰"""
    tools = get_news_tools()
    source_list = [s.strip() for s in sources.split(",") if s.strip()]
    data = []
    for src in source_list:
        items = tools.fetch_hot_news(src, count=count, fetch_content=False)
        data.append({
            "source": src,
            "source_name": tools.SOURCES.get(src, src),
            "items": items
        })
    return {
        "updated_at": datetime.now().isoformat(),
        "sources": data
    }


@app.post("/api/suggest-queries")
async def suggest_queries(request: dict):
    """ä½¿ç”¨ LLM æ ¹æ®æ–°é—»æ ‡é¢˜ç”Ÿæˆ 10 ä¸ªå€™é€‰ Query ä¾›ç”¨æˆ·é€‰æ‹©"""
    news_title = request.get("title", "")
    if not news_title:
        raise HTTPException(400, "éœ€è¦æä¾›æ–°é—»æ ‡é¢˜")
    
    try:
        import os
        from utils.llm.factory import get_model
        from agno.agent import Agent
        
        # Get model config from environment
        provider = os.getenv("LLM_PROVIDER", "deepseek")
        model_id = os.getenv("LLM_MODEL", "deepseek-chat")
        llm = get_model(provider, model_id)
        agent = Agent(model=llm, markdown=False)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½é‡‘èåˆ†æä¸“å®¶ã€‚åŸºäºä»¥ä¸‹æ–°é—»æ ‡é¢˜ï¼Œç”Ÿæˆ 10 ä¸ªä¸åŒè§’åº¦çš„åˆ†ææŸ¥è¯¢ï¼ˆQueryï¼‰ã€‚
è¿™äº› Query å°†ç”¨äºé©±åŠ¨é‡‘èä¿¡å·åˆ†æç³»ç»Ÿï¼Œéœ€è¦è¦†ç›–ä¸åŒçš„åˆ†æç»´åº¦ã€‚

æ–°é—»æ ‡é¢˜ï¼š{news_title}

è¯·ç”Ÿæˆ 10 ä¸ªæŸ¥è¯¢ï¼Œæ¯ä¸ªæŸ¥è¯¢åº”è¯¥ï¼š
1. ä»ä¸åŒè§’åº¦åˆ‡å…¥ï¼ˆå¦‚ï¼šè¡Œä¸šå½±å“ã€ä¸ªè‚¡æœºä¼šã€é£é™©è­¦ç¤ºã€å®è§‚å…³è”ç­‰ï¼‰
2. ç®€æ´æ˜ç¡®ï¼Œé€‚åˆä½œä¸ºåˆ†æä»»åŠ¡çš„è¾“å…¥
3. è¦†ç›–çŸ­æœŸå’Œä¸­é•¿æœŸè§†è§’

è¯·æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œåªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š
["æŸ¥è¯¢1", "æŸ¥è¯¢2", ...]"""

        response = agent.run(prompt)
        content = response.content if hasattr(response, 'content') else str(response)
        
        # Parse JSON from response
        import re
        json_match = re.search(r'\[.*\]', content, re.DOTALL)
        if json_match:
            queries = json.loads(json_match.group())
            # Allow up to 10, but accept fewer
            queries = [q for q in queries if isinstance(q, str) and q.strip()][:10]
        else:
            # Fallback: split by lines and clean
            queries = [line.strip().strip('"').strip("'") for line in content.split('\n') if line.strip()]
            queries = [q for q in queries if q and not q.startswith('[') and not q.startswith(']')][:10]
        
        # If no valid queries parsed, add the original title as fallback
        if not queries:
            queries = [news_title]
        
        return {
            "title": news_title,
            "suggestions": queries
        }
    except Exception as e:
        logger.error(f"Query suggestion failed: {e}")
        # Fallback: return basic variations
        return {
            "title": news_title,
            "suggestions": [
                f"{news_title} å¯¹Aè‚¡çš„å½±å“",
                f"{news_title} ç›¸å…³æ¦‚å¿µè‚¡",
                f"{news_title} æŠ•èµ„æœºä¼šåˆ†æ",
                f"{news_title} é£é™©æç¤º",
                f"{news_title} è¡Œä¸šå½±å“",
                news_title
            ]
        }

@app.get("/api/run/{run_id}")
async def get_run(run_id: str):
    """è·å–è¿è¡Œè¯¦æƒ…"""
    db = get_db()
    run = db.get_run(run_id)
    if not run:
        raise HTTPException(404, "è¿è¡Œè®°å½•ä¸å­˜åœ¨")
    
    steps = db.get_steps(run_id)
    return {
        "run": run.model_dump(),
        "steps": [s.model_dump() for s in steps]
    }


@app.get("/api/run/{run_id}/data")
async def get_run_data(run_id: str):
    """è·å–è¿è¡Œçš„ç»“æ„åŒ–æ•°æ® (signals, charts, graph)"""
    db = get_db()
    run = db.get_run(run_id)
    if not run:
        raise HTTPException(404, "è¿è¡Œè®°å½•ä¸å­˜åœ¨")
    
    data = db.get_run_data(run_id)
    result = data or {
        "signals": [],
        "charts": {},
        "graph": {}
    }

    # Load structured report from checkpoint if not in DB
    if "report_structured" not in result:
        try:
            from utils.checkpointing import CheckpointManager
            ckpt = CheckpointManager("reports/checkpoints", run_id)
            if ckpt.exists("report_structured.json"):
                result["report_structured"] = ckpt.load_json("report_structured.json")
        except Exception as e:
            logger.warning(f"Failed to load report_structured for {run_id}: {e}")
    
    # Filter out charts without valid prices to prevent frontend crashes
    if "charts" in result and isinstance(result["charts"], dict):
        valid_charts = {
            k: v for k, v in result["charts"].items()
            if v and isinstance(v.get("prices"), list) and len(v.get("prices", [])) > 0
        }
        result["charts"] = valid_charts
    
    # Read report content if available
    report_content = None
    report_path = run.report_path
    if report_path:
        report_file = Path(report_path)
        if not report_file.is_absolute():
            report_file = Path(__file__).parent.parent / report_file
        if report_file.exists():
            try:
                with open(report_file, "r", encoding="utf-8") as f:
                    report_content = f.read()
            except Exception as e:
                logger.error(f"Failed to read report file {report_file}: {e}")
            
    result["report_content"] = report_content
    result["report_path"] = report_path
    
    return {
        "run_id": run_id,
        **result
    }

@app.delete("/api/run/{run_id}")
async def delete_run(run_id: str, confirm: bool = False):
    """åˆ é™¤è¿è¡Œè®°å½•"""
    if not confirm:
        raise HTTPException(400, "è¯·ç¡®è®¤åˆ é™¤æ“ä½œ (confirm=true)")
    
    db = get_db()
    if db.delete_run(run_id):
        return {"message": f"å·²åˆ é™¤è¿è¡Œè®°å½•: {run_id}"}
    raise HTTPException(404, "è¿è¡Œè®°å½•ä¸å­˜åœ¨")


@app.post("/api/run/{run_id}/rerun")
async def rerun(run_id: str):
    """é‡æ–°è¿è¡Œç›¸åŒçš„æŸ¥è¯¢"""
    db = get_db()
    old_run = db.get_run(run_id)
    if not old_run:
        raise HTTPException(404, "è¿è¡Œè®°å½•ä¸å­˜åœ¨")
    
    # ä½¿ç”¨ç›¸åŒå‚æ•°åˆ›å»ºæ–°ä»»åŠ¡
    request = RunRequest(
        query=old_run.query,
        sources=old_run.sources
    )
    return await start_run(request)


@app.post("/api/run/{run_id}/update")
async def update_run_endpoint(run_id: str, request: RunRequest):
    """
    æ›´æ–°è¿è¡Œè®°å½•ï¼šåŸºäºæ—§ Run + æ–°è¡Œæƒ…ç”Ÿæˆæ–°æŠ¥å‘Š
    request.query å¯ç”¨äºä¼ é€’é™„åŠ æŒ‡ä»¤
    """
    db = get_db()
    
    # Check current running state
    if run_state.status == "running":
        raise HTTPException(400, "å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œè¯·ç¨å€™")

    old_run = db.get_run(run_id)
    if not old_run:
        raise HTTPException(404, "è¿è¡Œè®°å½•ä¸å­˜åœ¨")
    
    # Create placeholder run entry (actual ID created by workflow, but let's pre-announce)
    # Actually workflow.update_run creates the new ID.
    # To conform to UI expectations, we might want to return the 'future' ID or just start it.
    # But integration logic makes it tricky to know ID upfront.
    # Simplified approach: We let the workflow create it, and UI listens to WebSocket for 'init' or 'connected'.
    # HOWEVER, run_state needs an ID to broadcast correctly.
    
    # Generate the REAL ID here to ensure alignment
    new_run_id = datetime.now().strftime('%Y%m%d_%H%M%S')
    run_state.reset(new_run_id)

    # Create run record upfront so UI/DB can track status
    new_run = DashboardRun(
        run_id=new_run_id,
        query=old_run.query,
        sources=old_run.sources,
        status="running",
        started_at=datetime.now().isoformat(),
        parent_run_id=run_id
    )
    db.create_run(new_run)
    
    asyncio.create_task(execute_update_workflow(run_id, request.query, new_run_id))
    return {"message": "Update started", "base_run_id": run_id, "run_id": new_run_id}

async def execute_update_workflow(base_run_id: str, user_query: Optional[str], new_run_id: str):
    """Execute update logic"""
    from .integration import dashboard_callback, workflow_runner
    db = get_db()
    loop = asyncio.get_event_loop()
    
    async def async_broadcast(message: dict):
        msg_type = message.get("type")
        data = message.get("data", {})

        if msg_type == "progress":
            run_state.phase = data.get("phase", "")
            run_state.progress = data.get("progress", 0)
        elif msg_type == "step":
            # Save steps to DB for update runs
            step = DashboardStep(
                run_id=new_run_id,
                step_type=data.get("type", ""),
                agent=data.get("agent", ""),
                content=data.get("content", ""),
                timestamp=data.get("timestamp", datetime.now().isoformat())
            )
            db.add_step(step)

        await run_state.broadcast(message)

    dashboard_callback.enable(async_broadcast, loop)
    
    try:
        run_state.status = "running"
        workflow_runner.update_run_async(
            base_run_id, 
            run_state=run_state, 
            user_query=user_query, 
            new_run_id=new_run_id
        )
        
        while workflow_runner.is_running():
            await asyncio.sleep(0.5)
            
        # Post-processing: Sync the newly created run to SQLite
        try:
            from utils.checkpointing import CheckpointManager
            ckpt = CheckpointManager("reports/checkpoints", new_run_id)
            state = ckpt.load_json("state.json") if ckpt.exists("state.json") else {}

            # Load updated signals from checkpoint
            analyzed_signals = ckpt.load_json("analyzed_signals.json") if ckpt.exists("analyzed_signals.json") else []

            # Fallback to base run data if needed
            base_data = db.get_run_data(base_run_id) or {}
            signals = analyzed_signals or base_data.get("signals", [])

            # Rebuild charts with latest prices when possible
            charts: Dict[str, Dict] = dict(base_data.get("charts", {}) or {})
            try:
                workflow = workflow_runner._ensure_workflow()
                stock_tools = workflow.trend_agent.stock_toolkit._stock_tools
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d')
                updated_tickers = set()
                for signal in signals:
                    for item in signal.get("impact_tickers", []) or []:
                        if isinstance(item, dict):
                            ticker_code = item.get("ticker")
                            ticker_name = item.get("name")
                        else:
                            ticker_code = str(item)
                            ticker_name = str(item)
                        if not ticker_code or ticker_code in updated_tickers:
                            continue
                        try:
                            df = stock_tools.get_stock_price(ticker_code, start_date, end_date)
                            if df is not None and not df.empty:
                                chart_data = workflow_runner._format_chart_from_df(
                                    ticker_code,
                                    ticker_name or ticker_code,
                                    df,
                                    news_text=signal.get("summary") or signal.get("title", ""),
                                    prediction_logic=signal.get("summary")
                                )
                                charts[ticker_code] = chart_data
                                updated_tickers.add(ticker_code)
                        except Exception as e:
                            logger.warning(f"Chart refresh failed for {ticker_code}: {e}")
            except Exception as e:
                logger.warning(f"Chart rebuild skipped: {e}")

            structured = None
            if ckpt.exists("report_structured.json"):
                structured = ckpt.load_json("report_structured.json")

            run_data = {
                "signals": signals,
                "charts": charts,
                "graph": base_data.get("graph", {}),
                "report_structured": structured
            }
            db.save_run_data(new_run_id, run_data)

            db.update_run(
                new_run_id,
                status=state.get("status", "completed"),
                finished_at=state.get("finished_at"),
                report_path=state.get("output"),
                signal_count=len(signals)
            )

            run_state.output = state.get("output")
            run_state.status = "completed"
            await run_state.broadcast({
                "type": "completed",
                "data": {"run_id": new_run_id, "parent_run_id": base_run_id}
            })
            logger.info(f"âœ… Synced updated run {new_run_id} to DB")
        except Exception as e:
            logger.error(f"Failed to sync update to DB: {e}")
        
    except Exception as e:
        run_state.status = "failed"
        await run_state.broadcast({"type": "error", "data": {"message": str(e)}})
    finally:
        dashboard_callback.disable()
        if run_state.status == "running":
            run_state.status = "idle"


# ============ å·¥ä½œæµæ‰§è¡Œ ============
async def execute_workflow(run_id: str, request: RunRequest):
    """æ‰§è¡ŒçœŸå®çš„ AlphaEar å·¥ä½œæµ"""
    from .integration import dashboard_callback, workflow_runner
    
    db = get_db()
    loop = asyncio.get_event_loop()
    
    async def async_broadcast(message: dict):
        """å¤„ç†å›è°ƒæ¶ˆæ¯å¹¶å¹¿æ’­"""
        msg_type = message.get("type")
        data = message.get("data", {})
        
        if msg_type == "progress":
            run_state.phase = data.get("phase", "")
            run_state.progress = data.get("progress", 0)
        
        elif msg_type == "step":
            # ä¿å­˜åˆ°æ•°æ®åº“
            step = DashboardStep(
                run_id=run_id,
                step_type=data.get("type", ""),
                agent=data.get("agent", ""),
                content=data.get("content", ""),
                timestamp=data.get("timestamp", datetime.now().isoformat())
            )
            db.add_step(step)
        
        elif msg_type == "signal":
            run_state.signals.append(data)
        
        elif msg_type == "chart":
            ticker = data.get("ticker")
            if ticker:
                run_state.charts[ticker] = data
        
        elif msg_type == "graph":
            run_state.transmission_graph = data
        
        # å¹¿æ’­åˆ°æ‰€æœ‰å®¢æˆ·ç«¯
        await run_state.broadcast(message)
    
    # å¯ç”¨å›è°ƒ
    dashboard_callback.enable(async_broadcast, loop)
    
    try:
        run_state.status = "running"
        
        # åœ¨åå°çº¿ç¨‹å¯åŠ¨å·¥ä½œæµ
        sources_value = request.sources
        if isinstance(sources_value, list):
            sources_list = sources_value
        else:
            sources_text = sources_value or "financial"
            sources_list = [s.strip() for s in sources_text.split(",") if s.strip()]
        
        workflow_runner.run_async(
            query=request.query,
            sources=sources_list,
            wide=request.wide,
            depth=request.depth,
            run_state=run_state
        )
        
        # ç­‰å¾…å·¥ä½œæµå®Œæˆ
        while workflow_runner.is_running():
            await asyncio.sleep(0.5)
        
        # æ›´æ–°æ•°æ®åº“
        db.update_run(
            run_id,
            status="completed",
            finished_at=datetime.now().isoformat(),
            signal_count=len(run_state.signals),
            report_path=run_state.output
        )
        
        # ä¿å­˜ç»“æ„åŒ–æ•°æ® (ç”¨äºäº¤äº’å¼æ¸²æŸ“å’Œå¯¹æ¯”)
        logger.info(f"ğŸ“Š Saving run data: {len(run_state.signals)} signals, {len(run_state.charts)} charts")
        run_data = {
            "signals": run_state.signals,
            "charts": run_state.charts,
            "graph": run_state.transmission_graph,
            "report_structured": run_state.report_structured
        }
        db.save_run_data(run_id, run_data)
        
        run_state.status = "completed"
        
        # å¹¿æ’­å®Œæˆ
        await run_state.broadcast({
            "type": "completed",
            "data": {
                "run_id": run_id,
                "signal_count": len(run_state.signals)
            }
        })
        
    except Exception as e:
        db.update_run(
            run_id,
            status="failed",
            finished_at=datetime.now().isoformat(),
            error_message=str(e)
        )
        run_state.status = "failed"
        
        await run_state.broadcast({
            "type": "error",
            "data": {"message": str(e)}
        })
    
    finally:
        dashboard_callback.disable()


# ============ é™æ€æ–‡ä»¶æœåŠ¡ ============
# React æ„å»ºäº§ç‰©
frontend_dist = Path(__file__).parent / "frontend" / "dist"
reports_dir = Path("reports")
if reports_dir.exists():
    app.mount("/reports", StaticFiles(directory=reports_dir), name="reports")

if frontend_dist.exists():
    app.mount("/assets", StaticFiles(directory=frontend_dist / "assets"), name="assets")
    
    @app.get("/")
    async def serve_frontend():
        return FileResponse(frontend_dist / "index.html")
    
    @app.get("/{path:path}")
    async def serve_frontend_routes(path: str):
        # å¤„ç† React Router è·¯ç”±
        file_path = frontend_dist / path
        if file_path.exists() and file_path.is_file():
            return FileResponse(file_path)
        return FileResponse(frontend_dist / "index.html")
else:
    @app.get("/")
    async def no_frontend():
        return {
            "message": "å‰ç«¯æœªæ„å»º",
            "hint": "è¯·è¿è¡Œ: cd dashboard/frontend && npm run build"
        }


# ============ å…¥å£ ============
if __name__ == "__main__":
    uvicorn.run(
        "dashboard.server:app",
        host="0.0.0.0",
        port=8765,
        reload=True
    )
